# MySQL

## MySQL架构

MySQL的逻辑架构主要包括四层

- 连接层
  - 线程池，处理连接处理，身份验证，基于SSL的安全校验等
- 服务层
  - 又叫 SQL Layer，主要完成大部分的核心服务功能， 如查询解析、优化、缓存、以及所有的内置函数（日期、时间、数学运算等），所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等
- 引擎层
  - 又叫 StorEngine Layer，底层数据存取操作实现部分，由多种存储引擎共同组成。负责存储和获取所有存储在MySQL中的数据，就像Linux众多的文件系统 一样。如 InnoDB 和 MyISAM。
- 存储层
  - 将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互

### Select语句执行过程

![img](https://ask.qcloudimg.com/http-save/yehe-4831778/9cd86591c0b6a8b6dcc994f4457ccbe8.png)

- 连接：客户端向 MySQL 服务器发送一条查询请求，与connectors交互，连接池认证相关处理。当该请求从等待队列进入到处理队列，管理器会将该请求丢给SQL接口。
  - 传输层用TCP，应用层是半双工，在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据
  - 建立连接的过程通常是比较复杂的，尽量使用长连接。但是全部使用长连接占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。可以定期断开长连接或者执行 mysql_reset_connection 来重新初始化连接资源。
- 缓存：将请求进行hash处理并与缓存中的结果进行对比，如果完全匹配则通过缓存直接返回处理结果。
  - 两个查询在任何字符上的不同 (例如 : 空格、注释)，都会导致缓存不会命中。
  - 如果这些表 (数据或结构) 发生变化，那么和这张表相关的所有缓存数据都将失效。所以如果是写密集型应用，慎用缓存。
- 解析：服务器进行SQL解析，词法分析、语法分析。
- 优化：再由优化器生成对应的执行计划。
  - 如select语句先用where优化，再优化过滤需要的列，而不是全部select出来再优化。
  - 表里面有多个索引的时候，决定使用哪个索引
  - 重新定义表的关联顺序 (多张表关联查询如 join  时，并不一定按照 SQL 中指定的顺序进行）
  - 提前终止查询，如 : 使用 Limit
- 执行：MySQL 根据执行计划，调用存储引擎的 API来执行查询。
  - 检查表权限

### 更新语句执行过程

- 连接
- 清除表查询缓存
- 解析：服务器进行SQL解析，词法分析、语法分析。
- 优化：再由优化器生成对应的执行计划。
- 执行器执行
  - 检查表权限
  - 获取行锁
  - 取数据，如果目标数据存在内存中，直接返回，否则，需要先从磁盘读入内存，然后再返回
  - 更新数据，调用引擎接口，将新数据更新到**内存**
  - 写 redo log，将这个更新操作记录到 redo log buffer，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
  - 提交事务
    - 写 binlog，执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
    - 将 `Redo Log Buffer` 中的内容采用追加写的方式刷新到磁盘的 `Redo Log File`。
    - 释放行锁
    - 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

[MySQL架构原理(详解)-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1981543)

## 存储引擎

InnoDB 现在是 MySQL 默认的存储引擎。一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求。

InnoDB 物理文件结构为：

- `.frm` 文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等
  - 与数据库存储引擎无关，任何存储引擎的数据表都必须有`.frm`文件，命名方式为 数据表名.frm，如user.frm。
- `.ibd` 文件或 `.ibdata` 文件：存放 InnoDB 数据的文件

InnoDB 特性

- 支持事务（MyISAM 不支持）
- 支持外键（MyISAM 不支持）
- 聚簇索引（MyISAM 非聚簇索引）
  - 聚簇索引，数据和索引不分离，文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。
  - 但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。
  -  MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
- 最小的锁粒度是行锁（MyISAM 是表锁）
- InnoDB 不保存表的具体行数，执行`select count(*) from table` 时需要全表扫描。（MyISAM 会计数）
- InnoDB 支持在线热备份（MyISAM 不支持）
  - 在数据库运行的同时备份数据，更加省时省力，能够避免服务停机时间过长的问题。

## 数据类型

主要包括以下五大类：

- 整数类型：bit, bool, int, bigint
- 浮点数类型：float, double, decimal
- 字符串类型：char（固定长度）, varchar（可变长度）, text 
- 日期类型：Date、DateTime、TimeStamp、Time、Year
- 其他数据类型：binary、enum、set

## 索引

索引（Index）是帮助MySQL高效获取数据的数据结构，所以索引的本质是可以快速查找的数据结构。它大大减少了服务器需要扫描的数据行数，也可以帮助服务器避免进行排序和分组，将随机 I/O 变为顺序 I/O。

但是索引本身也很大，一般以索引文件的形式存储在磁盘上，会消耗一部分内存和磁盘空间，而且会降低更新表的速度。

索引是在存储引擎层实现的，不是server层面。

### 数据结构

AVL树，树高差只有1，高度平衡，查询快，rebalance频率高，更新慢

红黑树，确保没有一条路径会比其他路径长2倍，近似平衡，rebalance频率低

B树，平衡，单个节点信息多，高度低，磁盘IO低

#### B树

系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来。

InnoDB 存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为16KB，可通过参数设置。

InnoDB 在据读入磁盘时会以页为基本单位，页的大小大于块，这将会减少磁盘I/O次数，提高查询效率。

B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。B-Tree 的每个节点占用一个磁盘块。

一条记录为一个二元组[key, data] ，key为记录的键值，如主键值，data 为一行记录中除主键外的数据。

一棵m阶的B-Tree

- 每个节点最多有m个孩子，除了根节点和叶子节点外，每个节点至少有m/2个孩子。
- 若根节点不是叶子节点，则至少有2个孩子。
- 一个节点上有 m-1 个升序排序的 key 和 m 个指向子树根节点的指针

如一棵三阶B-Tree

![img](https://ask.qcloudimg.com/http-save/yehe-2947935/2qdgqaxj3f.png)

#### B+树

InnoDB中索引的默认数据结构是B+树。

B+Tree相对于B-Tree不同：

- 非叶子节点只存储键值信息，数据记录都存放在叶子节点中
  - 一个页内可存放的 key 数量增加，降低树的深度，降低磁盘IO次数，提高查询效率。B+Tree的高度一般都在2-4层，最多只需要1~3次磁盘I/O操作。
    - 总数据为N，磁盘块的数据项数量是m，h=log(m+1)N
  - 提高随机查找的效率，查询效率更加稳定
- 所有叶子节点之间都有一个链指针（双向链表）
  - 提高有范围的顺序查找效率（相比于普通Hash，具有顺序性）

![img](https://ask.qcloudimg.com/http-save/yehe-2947935/rpnddj90bf.jpeg)

当b+树的数据项是复合的数据结构（多列索引），比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，如果name相同再依次比较age和sex，最后得到检索的数据，即**索引的最左匹配特性**。

### 其他

#### 聚簇索引

**InnoDB的数据文件本身就存放于主键索引文件中**。

- 对于主索引，数据域会存放表中所有的数据记录（所以InnoDB必须要有主键，并且推荐使用整型自增主键）
- 对于辅助索引，数据域会引用主键，检索的时候先找打主键，再通过主键索引找到数据行（回表查询）

#### 索引覆盖

覆盖索引指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取，不需要回表操作

- 就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说**查询列要被所建的索引覆盖**。

#### 索引下推

索引下推(Index Condition Pushdown) ICP 是Mysql5.6之后新增的功能，主要的核心点就在于把数据筛选的过程放在了存储引擎层去处理，而不是像之前一样放到Server层去做过滤。

使用ICP之后我们就是简单的通过联合索引中本来就有的数据直接过滤了，不需要再查到一堆无用的数据去Server层进行过滤，这样的话减少了回表的次数和返回的数据，IO次数减少了，对性能有很好的提升。

如，where里同时有主键索引和联合索引

ICP前

- 存储引擎根据联合索引找到所有符合条件的数据
- 回表查询，再过滤出满足主键索引条件的数据

ICP后

- 存储引擎根据联合索引找到所有符合条件的数据，同时再过滤出满足主键索引条件的数据
- 回表查询

[索引下推，这个点你肯定不知道！ (qq.com)](https://mp.weixin.qq.com/s/87qsrj-_hG54uxcOlFr35Q)

#### 索引建议

1. 主键自动建立唯一索引
2. 频繁作为查询条件的字段
3. 查询中与其他表关联的字段，外键关系建立索引
4. 查询中排序的字段，排序字段通过索引访问大幅提高排序速度
5. 查询中统计或分组字段
6. 需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好（让选择性最强的索引列放在前面）
6. 全值匹配
6. <，<=，=，>，>=，BETWEEN，IN 可用到索引， <>，not in ，!= 则不行，会导致全表扫描
6. like "xxxx%" 是可以用到索引的，like "%xxxx" 则不行(like "%xxx%" 同理)。like以通配符开头('%abc...')索引失效会变成全表扫描的操作
6. is null ,is not null 也无法使用索引
6. 不要在索引上做任何操作（计算、函数、自动/手动类型转换），不然会导致索引失效而转向全表扫描
6. 索引字段使用 or 时，会导致索引失效而转向全表扫描

## 日志

MySQL中包含以下几种日志

- 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。
- 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。
- 慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。
- binlog：记录对数据库执行更改的所有操作。
- 事务日志：重做日志redo和回滚日志undo

### Redo log

- InnoDB 存储引擎层的日志
- 物理日志，存储了数据被修改的值
- 在数据库重启恢复的时候被使用，恢复速度远快于逻辑日志。
- 记录事务操作的变化，不管事务是否提交都会记录下来。有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，以此来保证数据的完整性。这个能力称为crash-safe（binlog也可保证该能力）。
- WAL技术（Write-Ahead-Logging，预写日志）
  - 由于每次的更新操作都需要写进磁盘，然后磁盘也要找到对应记录，进行更新，整个过程的IO成本、查找成本都很高。所以可以先写日志，再写磁盘。
  - 过程
    - 将目标数据从磁盘中读入内存中来，并再内存中修改数据
    - 生成一条日志并写入 `Redo Log Buffer`，记录的是数据被修改后的值。
    - 当事务 commit 时，将 `Redo Log Buffer` 中的内容采用追加写的方式刷新到磁盘的 `Redo Log File`
    - 定期将内存中修改的数据刷新到数据文件（磁盘）中
- Redo log是大小固定的循环日志（多个日志文件，默认每个256M），志文件写满后会覆盖掉最先的记录
  - `write pos`：当前记录的位置，一边写一边后移，当写到第 3 号文件末（末尾）时会回到 0 号文件（开头）开头。
  - `checkpoint`：当前要擦除的位置，同样是往后推移并且循环的，擦除记录前要把记录更新到数据文件（更新到磁盘里）。
  - `write pos`和`checkpoint`之间：redo log 日志文件还空着的部分，可以用来记录新的操作。
    - 如果 `write pos` 追上 `checkpoint`，表示 `redo log` 日志文件写满了，此时不能再执行新的更新操作，会将记录写入数据文件，并执行擦除记录，推进 `checkpoint` 位置。
  - <img src="https://img.jbzj.com/file_images/article/202403/202432582915601.jpg" alt="img" style="zoom:50%;" />

- 通过 `innodb_flush_log_at_trx_commit` 参数来控制真实数据从内存刷盘的频率
  - 0：提交事务时，不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。
  - 1: 提交事务时，写入os buffer并调用fsync()刷到log file on disk中。
  - 2: 提交事务时，仅写入到os buffer，然后每秒调用fsync()将os buffer中的日志写入到log file on disk
  - ![img](https://ask.qcloudimg.com/http-save/yehe-4831778/db3b5d2f1ed4c423bd5264f3239bb83f.png)

#### Undo log

- InnoDB 存储引擎的日志
- 主要作用
  - 事务回滚
  - 实现多版本控制(MVCC)

### Binlog

- binlog是MySQL Server层记录的日志
- 逻辑日志，存储修改sql的语句逻辑
- 追加写，以二进制的形式记录的是这个语句的原始逻辑
- 主要作用：主从复制
- binlog不循环，不会覆盖之前的记录，会一直写

[详解MySQL更新语句的执行流程_Mysql_脚本之家 (jb51.net)](https://www.jb51.net/database/318453hiq.htm)

## 事务

MySQL处理事务处理的原则：ACID。

### ACID

A (Atomicity，原子性)

- 要求每次事务操作是原子的，要么事务中所有的操作都成功，要么一个都不执行。若一个失败，则全部回滚。
- 原子性的实现方式
  - redo log（重做日志）
    - 提供事务的持久性
    - 当事务发生时，所有的修改操作并不会直接写入数据文件，而是先写入redo log，并适时地刷新到磁盘上。
    - 在事务提交前系统突然崩溃，重启后也可以通过重做redo log中的操作来达到事务提交的状态，从而保证了事务的原子性。

  - undo log（撤销日志）
    - 提供事务可回滚的能力
    - 如果事务因为某种原因需要回滚，系统可以利用undo log中的信息撤销已经执行的操作，将数据库恢复到事务开始前的状态。


C (Consistency，一致性)

- 数据库事务必须保证数据库从一个一致的状态转变到另一个一致的状态。数据库的完整性约束（主键约束、外键约束和唯一性约束）必须始终保持满足。（保证数据库不存在非法的状态）
- 一致性的实现方式
  - MVCC（多版本并发控制），为每个事务提供数据的“快照”。在事务执行期间，即使其他事务修改了数据，该事务仍然看到的是它开始时的数据版本。这确保了事务内部的一致性，因为它不会看到其他事务的中间状态。
    - MVCC提供乐观锁机制，允许事务在不加锁的情况下读取数据。

  - 行锁，MVCC通常与行级锁定结合使用，只有被修改的行才会被锁定，有助于维护数据的一致性


I (Isolation，隔离性)

- 要求多个事务并发执行的时候，各个事务之间是隔离的，不能互相干扰。即每个事务都是一个黑盒，必须连续执行完内部所有的操作再执行下一个事务。
- 隔离性的实现方式
  - 悲观锁（悲观态度，认为一定会发生并发问题，所以先加上锁，事务提交或回滚后才释放锁）
    - 共享锁（读锁），允许多个事务同时读取同一资源，但阻止其他事务对该资源进行写操作。这保证了在读取数据时，数据不会被其他事务修改，从而实现了读操作的隔离。
    - 排他锁（写锁）， 当一个事务需要对资源进行写操作时，它会获得该资源的排他锁，阻止其他事务对该资源进行读或写操作。这确保了在修改数据时，数据不会被其他事务同时读取或修改，从而实现了写操作的隔离。
    - 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁，这两种意向锁都是**表锁**：
      - 意向共享锁（IS）：事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
      - 意向排他锁（IX）：事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。
    
  - 乐观锁（乐观态度，认为不会发生并发问题，不用加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务）
    - MVCC（多版本并发控制），读操作时可以不加锁，提高并发量，写操作获取排他锁。避免了脏读和不可重复读等问题。


D (Durability，持久性)

- 事务一旦被提交，它对数据库的改变就是永久性的，持久的。且不会被回滚。
- 持久化的实现方式
  - redo log/undo log/bin log
  - 双写缓冲（double write buffer）

#### 双写缓冲

 Linux文件系统页的大小默认是4KB。而MySQL的页大小默认是16KB。由于磁盘操作不是原子的，如果在写页的过程中发生系统崩溃或电源故障，就可能导致页的部分写入，只有页的一部分被写入磁盘，而其他部分仍然是旧的或损坏的数据。

InnoDB的redo日志虽然可以用来恢复数据，但它记录的是对页的物理更改（如“将页的偏移量XXX处的值更改为YYY”），而不是页的完整内容。因此，如果页发生了部分写入，redo日志可能无法完全恢复该页。

 为了解决这个问题，InnoDB引入了Doublewrite Buffer。Doublewrite Buffer是一个特殊的区域，它分为内存部分和磁盘部分

- 内存部分：Doublewrite Buffer在内存中维护了一个缓冲区，用于暂存即将写入磁盘的数据页。
- 磁盘部分：Doublewrite Buffer在磁盘上有一个固定的区域，用于存储从内存中刷新出来的数据页。

当InnoDB需要将一个修改后的数据页从内存刷新到磁盘时，步骤：

- 通过memcpy函数拷贝至内存中的Doublewrite Buffer中
- Doublewrite Buffer的内存里的数据页，会fsync刷到Doublewrite Buffer的磁盘上，分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB
- Doublewrite Buffer的内存里的数据页，再刷到数据磁盘存储.ibd文件上（离散写）

如果在写入磁盘过程中宕机，InnoDB可以在重启后从Doublewrite Buffer中恢复数据页。因为Doublewrite Buffer中存储的是数据页的完整内容。

如果在写入Doublewrite Buffer的过程中宕机，可通过原始磁盘页+redo log恢复数据。

### 隔离级别

#### 并发的三个问题

- 脏读
  - 读到了其他事务未提交的数据。如事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据。
- 不可重复度
  - 事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。
  - 针对 Update
- 幻读
  - 事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了增加或删除并提交，导致事务 A 多次读取同一数据时，结果不一致。
  - 针对 Insert 或 Delete

#### 数据库的四个隔离级别

- 读未提交 （Read uncommitted）
  - 一个事务可以读取另一个未提交事务的数据。可能会导致脏读、不可重复读和幻读。
- 读提交（Read Committed）
  - 只允许读取另一个事务已经提交的数据。可能会导致不可重复读和幻读。
- 可重复读（Repeated Read）
  - 一个事务内对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改。可能会导致幻读。
- 串行化
  - 最严格的事务，要求所有事务被串行执行，不能并发执行。

MySQL InnoDB 存储引擎的默认支持的隔离级别是 **可重复读**，同时使用Next-Key Lock 算法来避免幻读的产生，所以该模式达到了 SQL标准的 可串行化隔离级别，而且保留了比较好的并发性能。（直接使用串行化对并发性能有很大影响，通常不会使用）

#### 可重复读实现

- 启动事务时生成一个 Read View
  - Read View 中包含四个字段
    - m_ids，创建 Read View 时当前数据库中**活跃且未提交的事务的事务 id 列表**
    - min_trx_id，m_ids 的最小值
    - max_trx_id，m_ids 的最大值
    - creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**。
- 聚簇索引记录中会保存两个隐藏列
  - trx_id，一个事务对某条聚族索引记录进行改动时，会**把该事务的事务 id 记录在 trx_id 隐藏列里**
  - roll_pointer，一个指针，将该列的所有历史修改串起来

如：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcteHSfStxxCZ9XJia9z0VQ6vNwiblS89vQd1FEsCjI8JfNELEKy3KpjXQAMImmga0icYZvtqzAjiaTmw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

事务B对字段修改，事务A再读取时，发现该记录最新trx_id是52，对照read view发现是和自己同时启动的事务，那么就不会读取该记录，并继续往undo log 链寻找，直到找到满足的50。（该方法即是MVCC，多版本控制的实现）

<img src="C:\Users\10066\AppData\Roaming\Typora\typora-user-images\image-20240709194533147.png" alt="image-20240709194533147" style="zoom:50%;" />

#### 读提交实现

m_ids动态更新，每次检查trx_id是否在m_ids里，来判断数据是否可读。**不在 m_ids 列表里，说明该记录的 trx_id 的事务是已经提交过的了，于是事务 A 就可以读取这条记录**

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcteHSfStxxCZ9XJia9z0VQ6zcicwk676KAJiaPewibNyZNV0OreQicYbnu8o7ZsZpbZkibJ8ribiaaMEP5Jg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

[数据库事务 (qq.com)](https://mp.weixin.qq.com/s/iFmvvt4DJ-_qFeb0XUh6QA)

### 锁算法

**记录锁(Record Locks)**：单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项（如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用）

`SELECT * FROM table WHERE id = 1 FOR UPDATE`

**间隙锁（Gap Locks）**：当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”，InnoDB 也会对这个“间隙”加锁。

**使用间隙锁锁住的是一个区间（左开右开区间），而不仅仅是这个区间中的每一条数据**。 

`SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE;`（1，10不锁）

**临键锁(Next-key Locks)**：**记录锁与间隙锁的组合（左开右闭区间）**，它的封锁范围，既包含索引记录，又包含索引区间。

`InnoDB` 中行级锁是基于索引实现的。临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。

对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

## 主从复制

过程（三个线程）

- MySql主库在事务提交时会把数据变更记录在binlog中

- 从库启动复制，创建IO线程连接主库
- 主库创建binlog dump线程读取binlog并发送给IO线程
- IO线程获取数据后更新到从库的中继日志relay Log
- 从库的SQL线程读取中继日志relay Log并应用。MySQL 复制是异步且是串行化的。

MySQL也会通过读写分离来提升数据库的性能，主数据库用于读写，从数据库只用于读。

同步策略

- 全同步复制：主库强制同步日志到从库，等全部从库执行完才返回客户端，性能差
- 半同步复制：主库收到至少一个从库确认就认为操作成功，从库写入日志成功返回ack确认

## 分库分表

分库：一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。

分表

<img src="https://mmbiz.qpic.cn/mmbiz_png/HQKXnkPzzdvicqb0jicUN2oKCQY2uggMcicZ0bFAdHPZ6ANCtLF4agRV0dBvsHo5WVAUFgWQORHcX8SHVjAiaM3kzQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

分表逻辑在一个公共的，可复用的位置来实现。比如，实现一个本地依赖包，将分表逻辑写在公共的代码库里，每个需要调用服务的客户方都集成该公共包，就接入了自动分表的能力。

## 调优

- 表结构优化

- - 拆分字段
  - 字段类型的选择
  - 字段类型大小的限制
  - 合理的增加冗余字段
  - 新建字段一定要有默认值

- 索引方面

- - 索引字段的选择
  - 利用好mysql支持的索引下推，覆盖索引等功能
  - 唯一索引和普通索引的选择
  - 没有索引查找一个Key时间复杂度需要**O(n)**，有索引就降低到了**O(logn)**。

- 查询语句方面

- - 3.1避免索引失效
  - 3.2合理的书写where条件字段顺序
  - 3.3小表驱动大表
  - 3.4可以使用force index()防止优化器选错索引

- 分库分表

- 减少请求的数据量

  - 只返回必要的列：最好不要使用 SELECT * 语句。

  - 只返回必要的行：使用 LIMIT 语句来限制返回的数据。

  - 缓存重复查询的数据

- 减少服务器端扫描的行数
  - 索引
- 分解大连接查询
  - 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联
    - 让缓存更高效
    - 减少锁竞争
    - 更容易对数据库进行拆分
    - 查询本身效率也可能会有所提升
- 开启慢查询日志，调优慢查询

[重温MySQL的ACID实现原理：深入探索底层设计与机制-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2398497)

[MySQL 三万字精华总结 + 面试100 问，吊打面试官绰绰有余（收藏系列）-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1638033)

[国庆肝了8天整整2W字的数据库知识点 (qq.com)](https://mp.weixin.qq.com/s/J3kCOJwyv2nzvI0_X0tlnA)













































