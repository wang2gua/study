# MySQL

## MySQL架构

MySQL的逻辑架构主要包括四层

- 连接层
  - 线程池，处理连接处理，身份验证，基于SSL的安全校验等
- 服务层
  - 又叫 SQL Layer，主要完成大部分的核心服务功能， 如查询解析、优化、缓存、以及所有的内置函数（日期、时间、数学运算等），所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等
- 引擎层
  - 又叫 StorEngine Layer，底层数据存取操作实现部分，由多种存储引擎共同组成。负责存储和获取所有存储在MySQL中的数据，就像Linux众多的文件系统 一样。如 InnoDB 和 MyISAM。
- 存储层
  - 将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互

### Select语句执行过程

![img](https://ask.qcloudimg.com/http-save/yehe-4831778/9cd86591c0b6a8b6dcc994f4457ccbe8.png)

- 连接：客户端向 MySQL 服务器发送一条查询请求，与connectors交互，连接池认证，权限校验相关处理。当该请求从等待队列进入到处理队列，管理器会将该请求丢给SQL接口。
  - 检查账号密码对mysql的权限
  - 传输层用TCP，应用层是半双工，在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据
  - 建立连接的过程通常是比较复杂的，尽量使用长连接。但是全部使用长连接占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。可以定期断开长连接或者执行 mysql_reset_connection 来重新初始化连接资源。
- 缓存：将请求进行hash处理并与缓存中的结果进行对比，如果完全匹配则通过缓存直接返回处理结果。（8.0遗弃）
  - 两个查询在任何字符上的不同 (例如 : 空格、注释)，都会导致缓存不会命中。
  - 如果这些表 (数据或结构) 发生变化，那么和这张表相关的所有缓存数据都将失效。所以如果是写密集型应用，慎用缓存。
- 解析：服务器进行SQL解析，词法分析、语法分析。
- 优化：再由优化器生成对应的执行计划。
  - 如select语句先用where优化，再优化过滤需要的列，而不是全部select出来再优化。
  - 表里面有多个索引的时候，决定使用哪个索引
  - 重新定义表的关联顺序 (多张表关联查询如 join  时，并不一定按照 SQL 中指定的顺序进行）
  - 提前终止查询，如 : 使用 Limit
- 执行：MySQL 根据执行计划，调用存储引擎的 API来执行查询。
  - 检查表权限

### 更新语句执行过程

- 连接
- 清除表查询缓存
- 解析：服务器进行SQL解析，词法分析、语法分析。
- 优化：再由优化器生成对应的执行计划。
- 执行器执行
  - 检查表权限
  - 获取行锁
  - 取数据，如果目标数据存在内存中，直接返回，否则，需要先从磁盘读入内存，然后再返回
  - 更新数据，调用引擎接口，将新数据更新到**内存**
  - 写 redo log，将这个更新操作记录到 redo log buffer，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
  - 提交事务
    - 写 binlog，执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
    - 将 `Redo Log Buffer` 中的内容采用追加写的方式刷新到磁盘的 `Redo Log File`。
    - 释放行锁
    - 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

[MySQL架构原理(详解)-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1981543)

## 存储引擎

InnoDB 现在是 MySQL 默认的存储引擎。一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求。

InnoDB 物理文件结构为：

- `.frm` 文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等
  - 与数据库存储引擎无关，任何存储引擎的数据表都必须有`.frm`文件，命名方式为 数据表名.frm，如user.frm。
- `.ibd` 文件或 `.ibdata` 文件：存放 InnoDB 数据的文件

InnoDB 特性

- 支持事务（MyISAM 不支持）
- 支持外键（MyISAM 不支持）（性能太差，通常不用）
- 聚簇索引（MyISAM 非聚簇索引）
  - 聚簇索引，数据和索引不分离，文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。
  - 但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。
  -  MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
- 最小的锁粒度是行锁（MyISAM 是表锁）
- InnoDB 不保存表的具体行数，执行`select count(*) from table` 时需要全表扫描。（MyISAM 会计数）
- InnoDB 支持在线热备份（MyISAM 不支持）
  - 在数据库运行的同时备份数据，更加省时省力，能够避免服务停机时间过长的问题。

## 数据类型

主要包括以下五大类：

- 整数类型：bit, bool, int, bigint
- 浮点数类型：float, double, decimal
- 字符串类型：char（固定长度）, varchar（可变长度）, text 
- 日期类型：Date、DateTime、TimeStamp、Time、Year
- 其他数据类型：binary、enum、set

## 索引

索引（Index）是帮助MySQL高效获取数据的数据结构，所以索引的本质是可以快速查找的数据结构。它大大减少了服务器需要扫描的数据行数，也可以帮助服务器避免进行排序和分组，将随机 I/O 变为顺序 I/O。

但是索引本身也很大，一般以索引文件的形式存储在磁盘上，会消耗一部分内存和磁盘空间（一个索引一颗B+树），而且会降低更新表的速度。

索引是在存储引擎层实现的，不是server层面。

### 数据结构

AVL树，树高差只有1，高度平衡，查询快，rebalance频率高，更新慢

红黑树，确保没有一条路径会比其他路径长2倍，近似平衡，rebalance频率低

B树，平衡（增删改查均为logn），单个节点信息多，高度低，磁盘IO低

#### B树

系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来。

InnoDB 存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为16KB，可通过参数设置。

InnoDB 在据读入磁盘时会以页为基本单位，页的大小大于块，这将会减少磁盘I/O次数，提高查询效率。

B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。B-Tree 的每个节点占用一个磁盘块。

一条记录为一个二元组[key, data] ，key为记录的键值，如主键值，data 为一行记录中除主键外的数据。

一棵m阶的B-Tree

- 每个节点最多有m个孩子，除了根节点和叶子节点外，每个节点至少有m/2个孩子。
- 若根节点不是叶子节点，则至少有2个孩子。
- 一个节点上有 m-1 个升序排序的 key 和 m 个指向子树根节点的指针

如一棵三阶B-Tree

![img](https://ask.qcloudimg.com/http-save/yehe-2947935/2qdgqaxj3f.png)

#### B+树

InnoDB中索引的默认数据结构是B+树。

B+Tree相对于B-Tree不同：

- 非叶子节点只存储键值信息，数据记录都存放在叶子节点中
  - 一个页内可存放的 key 数量增加，降低树的深度，降低磁盘IO次数，提高查询效率。B+Tree的高度一般都在2-4层，最多只需要1~3次磁盘I/O操作。
    - 总数据为N，磁盘块的数据项数量是m，h=log(m+1)N
  - 同一层数据有序，可使用二分查找
  - 提高随机查找的效率，查询效率更加稳定
- 所有叶子节点之间都有一个链指针（双向链表）
  - 提高有范围的顺序查找效率（相比于普通Hash，具有顺序性）

![img](https://ask.qcloudimg.com/http-save/yehe-2947935/rpnddj90bf.jpeg)

当b+树的数据项是复合的数据结构（多列索引），比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，如果name相同再依次比较age和sex，最后得到检索的数据，即**索引的最左匹配特性**。

- 如果没有查询name，直接查询age，则无法使用索引

#### 其他索引结构

- 哈希索引：基于Hash算法，将索引列值转化成hash值。但是不支持范围查询以及排序
- 全文索引：用于对文本字段进行全文搜索，可以关键字模糊匹配

### 其他

#### 聚簇索引

**InnoDB的数据文件本身就存放于主键索引文件中**。

- 对于主索引，数据域会存放表中所有的数据记录（所以InnoDB必须要有主键，并且推荐使用整型自增主键），这种就是聚簇索引
- 对于辅助索引（也称为非主键索引，二级索引），数据域会引用主键，检索的时候先找打主键，再通过主键索引找到数据行（回表查询），这种就是非聚簇索引
  - 回表效率很低，因为回表时主键不连续，需要大量随机的磁盘IO。所以避免使用select *操作


#### 索引覆盖

覆盖索引指一个查询语句的执行只用从索引（二级索引）中就能够取得，不必从数据表中读取，不需要回表操作

- 就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说**查询列要被所建的索引覆盖**。
- 可以减少IO操作，提高查询速度，节约内存。

#### 索引下推

索引下推(Index Condition Pushdown) ICP 是Mysql5.6之后新增的功能，Innodb和MyISAM都支持，主要的核心点就在于把数据筛选的过程放在了存储引擎层去处理，而不是像之前一样放到Server层去做过滤。

使用ICP之后我们就是简单的通过联合索引中本来就有的数据直接过滤了，不需要再查到一堆无用的数据去Server层进行过滤，这样的话减少了回表的次数和返回的数据，IO次数减少了，对性能有很好的提升。

如，where里同时有主键索引和联合索引

ICP前

- 存储引擎根据联合索引找到所有符合条件的数据
- 回表查询，再过滤出满足主键索引条件的数据
- 总结：查二级索引，回表查主键索引，再过滤（查，查，过滤）

ICP后

- 存储引擎根据联合索引找到所有符合条件的数据，同时再过滤出满足主键索引条件的数据
- 回表查询
- 总结：查二级索引，过滤，再回表查主键索引（查，过滤，查）

[索引下推，这个点你肯定不知道！ (qq.com)](https://mp.weixin.qq.com/s/87qsrj-_hG54uxcOlFr35Q)

#### 索引建议

1. 主键自动建立唯一索引
2. 频繁作为查询条件的字段
3. 索引不是越多越好
4. 长字段不建索引
5. 读大于写时，建立索引
6. 经常在where后的字段，考虑建立联合索引，减少索引数量（使用联合索引需注意顺序和最左匹配原则）
7. 经常在order by，group by，distinct后的字段，建立索引
8. 需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好（让选择性最强的索引列放在前面）
9. 全值匹配
10. <，<=，=，>，>=，BETWEEN，IN 可用到索引， <>，not in ，!= 则不行，会导致全表扫描
11. like "xxxx%" 是可以用到索引的，like "%xxxx" 则不行(like "%xxx%" 同理)。like以通配符开头('%abc...')索引失效会变成全表扫描的操作
12. is null ,is not null 也无法使用索引
13. 不要在索引上做任何操作（计算、函数、自动/手动类型转换），不然会导致索引失效而转向全表扫描
6. 索引字段使用 or 时，会导致索引失效而转向全表扫描
6. 检查索引是否生效：explain {SQL语句}
6. 不建议使用索引：小表、写频繁表、读不频繁表、select *操作多、长text varchar字段。

## 日志

MySQL中包含以下几种日志

- 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。
- 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。
- 慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。
- binlog：记录对数据库执行更改的所有操作。
- 事务日志：重做日志redo和回滚日志undo

### Redo log

- InnoDB 存储引擎层的日志
- 物理日志，存储了数据被修改的值
- 在数据库重启恢复的时候被使用，恢复速度远快于逻辑日志。
- 记录事务操作的变化，不管事务是否提交都会记录下来。有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，以此来保证数据的完整性。这个能力称为crash-safe（binlog也可保证该能力）。
- WAL技术（Write-Ahead-Logging，预写日志）
  - 由于每次的更新操作都需要写进磁盘，然后磁盘也要找到对应记录，进行更新，整个过程的IO成本、查找成本都很高。所以可以先写日志，再写磁盘。
  - 过程
    - 将目标数据从磁盘中读入内存中来，并再内存中修改数据
    - 生成一条日志并写入 `Redo Log Buffer`，记录的是数据被修改后的值。
    - 当事务 commit 时，将 `Redo Log Buffer` 中的内容采用追加写的方式刷新到磁盘的 `Redo Log File`
    - 定期将内存中修改的数据刷新到数据文件（磁盘）中
- Redo log是大小固定的循环日志（多个日志文件，默认每个256M），志文件写满后会覆盖掉最先的记录
  - `write pos`：当前记录的位置，一边写一边后移，当写到第 3 号文件末（末尾）时会回到 0 号文件（开头）开头。
  - `checkpoint`：当前要擦除的位置，同样是往后推移并且循环的，擦除记录前要把记录更新到数据文件（更新到磁盘里）。
  - `write pos`和`checkpoint`之间：redo log 日志文件还空着的部分，可以用来记录新的操作。
    - 如果 `write pos` 追上 `checkpoint`，表示 `redo log` 日志文件写满了，此时不能再执行新的更新操作，会将记录写入数据文件，并执行擦除记录，推进 `checkpoint` 位置。
  - <img src="https://img.jbzj.com/file_images/article/202403/202432582915601.jpg" alt="img" style="zoom:50%;" />

- 通过 `innodb_flush_log_at_trx_commit` 参数来控制真实数据从内存刷盘的频率（刷盘属于系统调用，需要上下文切换，操作磁盘，效率低）
  - 0：提交事务时，不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。
  - 1: 提交事务时，写入os buffer并调用fsync()刷到log file on disk中。默认值
  - 2: 提交事务时，仅写入到os buffer，然后每秒调用fsync()将os buffer中的日志写入到log file on disk
  - ![img](https://ask.qcloudimg.com/http-save/yehe-4831778/db3b5d2f1ed4c423bd5264f3239bb83f.png)

### Undo log

- InnoDB 存储引擎的日志
- 主要作用
  - 事务回滚
  - 实现多版本控制(MVCC)

### Binlog

- binlog是MySQL Server层记录的日志
- 逻辑日志，存储修改sql的语句逻辑
- 追加写，以二进制的形式记录的是这个语句的原始逻辑
- 主要作用：主从复制
- binlog不循环，不会覆盖之前的记录，会一直写
- binlog的三种模式
  - Statement：记录每一条sql语句
  - Row：不记录sql语句，仅记录哪条记录被修改（占用存储空间更多）
  - Mixed：混合模式（二选一），正常使用Statement，特殊情况无法完成主从复制的情况使用Row
  - Statement和Mixed都可能导致主从复制的问题

[详解MySQL更新语句的执行流程_Mysql_脚本之家 (jb51.net)](https://www.jb51.net/database/318453hiq.htm)

## 事务

MySQL处理事务处理的原则：ACID。

### ACID

A (Atomicity，原子性)

- 要求每次事务操作是原子的，要么事务中所有的操作都成功，要么一个都不执行。若一个失败，则全部回滚。
- 原子性的实现方式
  - redo log（重做日志）
    - 提供事务的持久性
    - 当事务发生时，所有的修改操作并不会直接写入数据文件，而是先写入redo log，并适时地刷新到磁盘上。
    - 在事务提交前系统突然崩溃，重启后也可以通过重做redo log中的操作来达到事务提交的状态，从而保证了事务的原子性。

  - undo log（撤销日志）
    - 提供事务可回滚的能力
    - 如果事务因为某种原因需要回滚，系统可以利用undo log中的信息撤销已经执行的操作，将数据库恢复到事务开始前的状态。


C (Consistency，一致性)

- 数据库事务必须保证数据库从一个一致的状态转变到另一个一致的状态。数据库的完整性约束（主键约束、外键约束和唯一性约束）必须始终保持满足。（保证数据库不存在非法的状态）
- 一致性的实现方式
  - MVCC（多版本并发控制），为每个事务提供数据的“快照”。在事务执行期间，即使其他事务修改了数据，该事务仍然看到的是它开始时的数据版本。这确保了事务内部的一致性，因为它不会看到其他事务的中间状态。
    - MVCC提供乐观锁机制，允许事务在不加锁的情况下读取数据。

  - 行锁，MVCC通常与行级锁定结合使用，只有被修改的行才会被锁定，有助于维护数据的一致性


I (Isolation，隔离性)

- 要求多个事务并发执行的时候，各个事务之间是隔离的，不能互相干扰。即每个事务都是一个黑盒，必须连续执行完内部所有的操作再执行下一个事务。
- 隔离性的实现方式
  - 悲观锁（悲观态度，认为一定会发生并发问题，所以先加上锁，事务提交或回滚后才释放锁）
    - S锁，共享锁（读锁），允许多个事务同时读取同一资源，但阻止其他事务对该资源进行写操作。这保证了在读取数据时，数据不会被其他事务修改，从而实现了读操作的隔离。
      - Select xxx lock in share mode
    - X锁，排他锁（写锁）， 当一个事务需要对资源进行写操作时，它会获得该资源的排他锁，阻止其他事务对该资源进行读或写操作。这确保了在修改数据时，数据不会被其他事务同时读取或修改，从而实现了写操作的隔离。
      - select xxx for update
    - 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁，这两种意向锁都是**表锁**：
      - 意向共享锁（IS）：事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
      - 意向排他锁（IX）：事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。
      - IS和IX的作用在于上表级锁的时候（需要锁整张表的场景），可以快速判断是否可以上锁，不需要挨个字段判断
  - 乐观锁（乐观态度，认为不会发生并发问题，不用加锁，只在更新数据时再根据CAS版本号或时间戳判断是否有冲突，有则处理，无则提交事务）
    - MVCC（多版本并发控制），读操作时可以不加锁，提高并发量，写操作获取排他锁。避免了脏读和不可重复读等问题。
      - select id, name, version from table where id = 1
      - update table set name='x', version = version + 1 where id = 1 and version = current_version
  - 悲观锁适合并发多，写多读少的场景，每次加锁确保数据安全，吞吐量较低。乐观锁适合并发少，读多写少的场景，提高并发量。


D (Durability，持久性)

- 事务一旦被提交，它对数据库的改变就是永久性的，持久的。且不会被回滚。
- 持久化的实现方式
  - redo log/undo log/bin log
  - 双写缓冲（double write buffer）

#### 双写缓冲

 Linux文件系统页的大小默认是4KB。而MySQL的页大小默认是16KB。由于磁盘操作不是原子的，如果在写页的过程中发生系统崩溃或电源故障，就可能导致页的部分写入，只有页的一部分被写入磁盘，而其他部分仍然是旧的或损坏的数据。

InnoDB的redo日志虽然可以用来恢复数据，但它记录的是对页的物理更改（如“将页的偏移量XXX处的值更改为YYY”），而不是页的完整内容。因此，如果页发生了部分写入，redo日志可能无法完全恢复该页。

 为了解决这个问题，InnoDB引入了Doublewrite Buffer。Doublewrite Buffer是一个特殊的区域，它分为内存部分和磁盘部分

- 内存部分：Doublewrite Buffer在内存中维护了一个缓冲区，用于暂存即将写入磁盘的数据页。
- 磁盘部分：Doublewrite Buffer在磁盘上有一个固定的区域，用于存储从内存中刷新出来的数据页。

当InnoDB需要将一个修改后的数据页从内存刷新到磁盘时，步骤：

- 通过memcpy函数拷贝至内存中的Doublewrite Buffer中
- Doublewrite Buffer的内存里的数据页，会fsync刷到Doublewrite Buffer的磁盘上（idbata文件中，两个1MB的区域，可存储64个16KB的页），分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB
- Doublewrite Buffer的内存里的数据页，再刷到数据磁盘存储.ibd文件上（离散写）

如果在写入磁盘过程中宕机，InnoDB可以在重启后从Doublewrite Buffer中恢复数据页。因为Doublewrite Buffer中存储的是数据页的完整内容。

如果在写入Doublewrite Buffer的过程中宕机，可通过原始磁盘页+redo log恢复数据。

### 隔离级别

#### 并发的三个问题

- 脏读
  - 读到了其他事务未提交的数据。如事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据。
- 不可重复度
  - 事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。
  - 针对 Update
- 幻读
  - 事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了增加或删除并提交，导致事务 A 多次读取同一数据时，结果不一致。
  - 针对 Insert 或 Delete

#### 数据库的四个隔离级别

- 读未提交 （Read uncommitted）
  - 一个事务可以读取另一个未提交事务的数据。可能会导致脏读、不可重复读和幻读。
- 读提交（Read Committed）
  - 只允许读取另一个事务已经提交的数据。可能会导致不可重复读和幻读。
- 可重复读（Repeated Read）
  - 一个事务内对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改。可能会导致幻读。
- 串行化
  - 最严格的事务，要求所有事务被串行执行，不能并发执行。

MySQL InnoDB 存储引擎的默认支持的隔离级别是 **可重复读**，同时使用Next-Key Lock 算法来避免幻读的产生，所以该模式达到了 SQL标准的 可串行化隔离级别，而且保留了比较好的并发性能。（直接使用串行化对并发性能有很大影响，通常不会使用）

#### 可重复读实现

- 启动事务时生成一个 Read View（一个事务只有一个Read View）
  - Read View 中包含四个字段
    - m_ids，创建 Read View 时当前数据库中**活跃且未提交的事务的事务 id 列表**
    - min_trx_id，m_ids 的最小值
    - max_trx_id，m_ids 的最大值
    - creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**。
- 聚簇索引记录中会保存两个隐藏列
  - trx_id，一个事务对某条聚族索引记录进行改动时，会**把该事务的事务 id 记录在 trx_id 隐藏列里**
  - roll_pointer，一个指针，将该列的所有历史修改串起来

如：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcteHSfStxxCZ9XJia9z0VQ6vNwiblS89vQd1FEsCjI8JfNELEKy3KpjXQAMImmga0icYZvtqzAjiaTmw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

事务B对字段修改，事务A再读取时，发现该记录最新trx_id是52，对照read view发现是和自己同时启动的事务，那么就不会读取该记录，并继续往undo log 链寻找，直到找到满足的50。（该方法即是MVCC，多版本控制的实现）

数据链仅存在undolog中，表中的字段依然为最新值。

<img src="C:\Users\10066\AppData\Roaming\Typora\typora-user-images\image-20240709194533147.png" alt="image-20240709194533147" style="zoom:50%;" />

#### 读提交实现

m_ids动态更新，每次检查trx_id是否在m_ids里，来判断数据是否可读。**不在 m_ids 列表里，说明该记录的 trx_id 的事务是已经提交过的了，于是事务 A 就可以读取这条记录**

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcteHSfStxxCZ9XJia9z0VQ6zcicwk676KAJiaPewibNyZNV0OreQicYbnu8o7ZsZpbZkibJ8ribiaaMEP5Jg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

[数据库事务 (qq.com)](https://mp.weixin.qq.com/s/iFmvvt4DJ-_qFeb0XUh6QA)

##### 读提交可能存在的问题

读提交Statement主从复制的问题

<img src="C:\Users\10066\AppData\Roaming\Typora\typora-user-images\image-20240727213628216.png" alt="image-20240727213628216" style="zoom:67%;" />

由于是读已提交，所以插入5这条记录会被先保留到binlog持久化

binlog中保存的记录就是先插入，后删除，主从复制到从库中会导致和主库数据不一致。

当使用可重复读就不会出现这种情况，因为在事务Acommit前会先使用临键锁锁上，事务B无法提交，只能在A释放锁后提交，只能先删除后插入，保证了一致性。

### 锁算法

**记录锁(Record Locks)**：单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项（如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用）

`SELECT * FROM table WHERE id = 1 FOR UPDATE`

**间隙锁（Gap Locks）**：当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”，InnoDB 也会对这个“间隙”加锁。

**使用间隙锁锁住的是一个区间（左开右开区间），而不仅仅是这个区间中的每一条数据，主要用于在记录还没生成的时候，用于防止幻读**。 

`SELECT * FROM table WHERE id BETWEN 3 AND 5 FOR UPDATE;`（3，5不锁，锁即将插入的4）

**临键锁(Next-key Locks)**：**记录锁与间隙锁的组合（左开右闭区间）**，它的封锁范围，既包含索引记录，又包含索引区间。

`InnoDB` 中行级锁是基于索引实现的。临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。

对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

## 主从复制

过程（三个线程）

- MySql主库在事务提交时会把数据变更记录在binlog中

- 从库启动复制，创建IO线程连接主库
- 主库创建binlog dump线程读取binlog并发送给IO线程
- IO线程获取数据后更新到从库的中继日志relay Log
- 从库的SQL线程读取中继日志relay Log并应用。MySQL 复制是异步且是串行化的。

MySQL也会通过读写分离来提升数据库的性能，主数据库用于读写，从数据库只用于读。

同步策略

- 全同步复制：主库强制同步日志到从库，等全部从库执行完才返回客户端，性能差
- 半同步复制：主库收到k从库确认就认为操作成功（k可通过参数设置），从库写入日志成功返回ack确认

读写分离

- 抽象一个中间层（或者直接使用中间件），将读操作指向从数据库，写操作指向主库
- 常见的中间件：MySQL-Proxy，Mycat等

主从复制以及读写分离造成的延迟问题

- 使用缓存，但是需要权衡缓存和数据库的一致性问题
- 中间件设置关键业务读写都走主库，非关键业务读写分离
- 设置时间阈值，写后一定时间的读走主库

## 分库分表

分库：一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上（服务器）， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。

分表

<img src="https://mmbiz.qpic.cn/mmbiz_png/HQKXnkPzzdvicqb0jicUN2oKCQY2uggMcicZ0bFAdHPZ6ANCtLF4agRV0dBvsHo5WVAUFgWQORHcX8SHVjAiaM3kzQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

<img src="C:\Users\10066\AppData\Roaming\Typora\typora-user-images\image-20240727224736723.png" alt="image-20240727224736723" style="zoom:33%;" />

<img src="C:\Users\10066\AppData\Roaming\Typora\typora-user-images\image-20240727224801412.png" alt="image-20240727224801412" style="zoom:33%;" />

分表逻辑在一个公共的，可复用的位置来实现。比如，实现一个本地依赖包，将分表逻辑写在公共的代码库里，每个需要调用服务的客户方都集成该公共包，就接入了自动分表的能力。

分库分表后的问题

- 事务问题，必须使用分布式事务，较为复杂，且通常分布式事务只能满足最终一致性，需要权衡。
- join问题，分表需要join，效率降低。跨库无法直接join，可通过先后查询的方式，也可通过es宽表查询，也可以多存一些冗余字段来防止join
- 全局id唯一性问题，单库单表直接自增id，分库后需通过雪花算法或其他全局id生成来控制全局id的唯一。
- 排序问题，分表后无法直接排序，自行添加业务逻辑，或者中间件，或者es来排序。
- count问题，分表后无法直接count，自行添加业务逻辑，或者中间件，或者es来排序。

## 调优

- 表结构优化
- - 拆分字段
  - 字段类型的选择（能用int不用bigint、char，Varchar优于Char，资金相关用decimal）
  - 字段类型大小的限制
  - 合理的增加冗余字段
  - 新建字段一定要有默认值
- 索引方面
- - 索引字段的选择
  - 利用好mysql支持的索引下推，覆盖索引等功能
  - 唯一索引和普通索引的选择
  - 没有索引查找一个Key时间复杂度需要**O(n)**，有索引就降低到了**O(logn)**。
- 查询语句方面
- - 3.1避免索引失效
  - 3.2合理的书写where条件字段顺序
  - 3.3小表驱动大表
  - 无索引字段减少order by
  - 3.4可以使用force index()防止优化器选错索引
- 分库分表
- 减少请求的数据量

  - 只返回必要的列：最好不要使用 SELECT * 语句。
- 只返回必要的行：使用 LIMIT 语句来限制返回的数据。
  - 避免使用%LIKE
- 缓存重复查询的数据
- 减少服务器端扫描的行数
  - 索引
- 分解大连接查询
  - 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联
    - 让缓存更高效
    - 减少锁竞争
    - 更容易对数据库进行拆分
    - 查询本身效率也可能会有所提升
- 开启慢查询日志，调优慢查询

[重温MySQL的ACID实现原理：深入探索底层设计与机制-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2398497)

[MySQL 三万字精华总结 + 面试100 问，吊打面试官绰绰有余（收藏系列）-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1638033)

[国庆肝了8天整整2W字的数据库知识点 (qq.com)](https://mp.weixin.qq.com/s/J3kCOJwyv2nzvI0_X0tlnA)

## 常见面试题

### MySQL 是如何实现数据的排序的？

- 索引排序
  - Order by子句包含的字段为索引，且索引排序和Order by子句顺序一致
- filesort
  - 无法用索引排序时使用的主动排序
  - 通过sort_buffer_size控制sort_buffer大小，小于则直接在内存中排序，大于则用磁盘临时文件进行外部排序（归并排序，拆分多个小文件），效率较低
  - 内存排序包括双路排序和单路排序
    - 双路排序，select的字段大小超过了max_length_for_sort_data（默认1024字节），则mysql采用主键+排序字段在sort_buffer中进行排序，排完再回表查询select的列，需要两次查询
    - 单路排序，select的字段大小没有超过max_length_for_sort_data，mysql直接将select的字段都放到sort_buffer中排序，排序结果直接返回，无须回表，效率更高。

### Change buffer

用法

- 执行update命令时，如果buffer pool中不存在当前需要update的数据
- innodb会把数据更新到change buffer中
- 下次再访问时，把数据加载到buffer pool中，并应用change buffer的变更，保持数据的一致性。

优点

- 当二级索引页不存在buffer pool中时，避免了直接从磁盘进行随机IO的开销，在后面访问时再批量更新到buffer pool中（redolog会做持久化操作）

### MySQL如何实现事务

- 锁，防止数据并发修改，满足隔离性
- redolog，保存对数据库的修改，崩溃时恢复未提交的更改，满足持久性
- undolog，保存历史版本，事务回滚
- MVCC，保持非锁定的读需求，提高并发度，实现读已提交和可重复读

### MySQL长事务

一次操作设计非常大的数据，导致表中很多数据需要被锁很久，这就涉及到长事务问题。导致效率非常低下。

处理方案

- 拆操作，拆的时候尽量利用主键索引的有序条件
- 并行拆分的操作（行锁不冲突）

### MySQL死锁

MySQL出现死锁主要因为资源的循环依赖。

MyISAM只有表锁，不会出现死锁。Innodb有行锁，可能出现死锁。

Innodb有innodb_deadlock_detect功能可自动检测死锁，发生死锁自动回退事务释放锁。也有innodb_lock_wait_timeout，当获取锁的时间超过阈值时会自动释放锁回滚。

遇到死锁可通过show innodb status获取死锁日志信息。

降低死锁概率

- 避免大事务
- 更改数据库的隔离级别（权衡数据的事务隔离性）
- 开启死锁检测和等锁超时

### explain

explain主要用于SQL分析，输出一条sql的分析结果，可以用来做SQL调优

其中type是比较关键的信息，type的种类有

- system，查询的表只有一行（系统表，不常见）
- const，查询的表最多一行匹配结果，通常是主键，唯一索引查询
- eq_ref，join时仅访问一次这个表，通常是主键，唯一索引的join查询
- ref，使用非唯一索引进行查询
- range，会扫描表的一部分，而不是全部行，通常出现在范围查找中，效率较高
- index，扫描索引的所有行，而不是表的全部行
- all，性能最差，需要扫描所有行，通常没有where条件的查询

还有extra信息

- using index，使用索引覆盖
- using where，使用where过滤
- using filesort，需要使用外排序，效率较低，可以通过加复合索引避免外排序

还有rows信息，表示大约会扫描的行数，越低越好

### Count(1) Count(*) Count(列) 差别

- count(1)和count(*)功能相同，统计所有行数，包含null，官网表示效率相同。
- count(列)统计指定列不为null的行数，需要对null进行判断，效率比count(1)和count(*)低，如果是非空的主键，则差不多。

### Char和Varchar

- char，固定长度，mysql自动填充缺失字段到指定长度
- varchar，可变长度，存储的字符串与实际字符串相等，会额外增加1-2字节用于存储长度信息。但是在sort，order这些排序场景的内存分配中，按照固定内存进行保存。
- 推荐使用varchar

### SQL调优

- set global slow_query_log = 'ON'，开启慢查询日志
- 找到超过3s的SQL
- 使用explain进行分析

### join的建议

- 不推荐多表join，对每个表进行扫描，关联，匹配，消耗CPU和内存，效率低下
- 小表作为驱动表，被驱动表查询字段建立索引
  - select * from A join B on (A.a = B.a)
  - A为驱动表，将会全表查询
  - B为被驱动表，会按a字段查询B表，所以B表上a为索引，会提高查询效率。

### Delete、Drop、Truncate 有什么区别？

- delete用于删除行数据，保留表的结构和相关对象
  - delete会产生binlog redolog undolog，只是给数据打标记，并不实时删除，空间大小不变，可回滚
- drop用于删除表，包括结构和相关对象
  - 删除.frm和.idb文件，表空间回收（系统共享表空间除外），不可回滚
- truncate用于删除行数据，保留表的结构和相关对象
  - 不会记录回滚日志，无法回滚
- 性能 drop > truncate > delete

### Inner Join，Left Join，Right Join

- inner join，内连接，返回两个表满足条件的交集
- left join，外连接，返回左边所有行，右边匹配的行，右边没有匹配的返回null
  - 若左表1行对右表多行，则会返回每一种组合
- right join，外连接，返回右边所有行，左边匹配的行，左边没有匹配的返回null
  - 若右表1行对左表多行，则会返回每一种组合

### Buffer pool

Innodb的缓存包括两个缓存

- 查询缓存：MySQL 8.0已废除，用于直接缓存查询结果
- Innodb buffer pool：Innodb存储引擎层的缓存组件，缓存数据页、索引页。查询数据时，Innodb现在buffer pool中查找，否则从磁盘读取并缓存到buffer pool（以16kb，页为单位读取）。innodb_buffer_pool_size可调整buffer pool的大小，通常设置为物理内存的70% 80%。

buffer pool中的数据会被redolog做持久化，不用担心宕机丢失的问题。

buffer pool的淘汰机制：变形LRU

buffer pool分为老年代（old sublist）和新生代（new sublist），老年代默认占3/8，可通过参数调整比例。

新页面插入时，先插入老年代头部，若新页面在1s内再次被访问，不会迁移到新生代，1s后被访问才会迁移到新生代。

原因：

- 预读机制：innodb有预读机制，在读取连续多个页面后，后面的页面也会被异步预加载到buffer pool（空间局部性），但是预读的数据不一定被访问，所以如果直接加到新生代，可能会淘汰大量的热点数据，加到老年代就没有这个问题。
- 大规模数据：mysql出现大规模数据扫描和访问（如不带where的select），可能直接将大部分数据直接移动到新生代头部，淘汰热点数据，但是如果1s后再次访问，那可能就是别的业务请求，属于热点数据，可以移动到新生代头部。

### 数据库隔离级别建议

默认隔离级别是可重复读，但是很多公司改成读已提交，目的是为了提高并发和降低死锁概率（可重复读比读提交多了间隙锁和临键锁，锁的数据更多）。

### 数据库不停服迁移怎么做？

迁移数据库需要考虑的问题

- 数据量，大
- 不停服务，保证数据一致性
- 出现问题需要回滚到老库，对业务产生的影响

解决方案：双写

- 新库和旧库进行数据同步（可使用主从同步的方案），先同步全量数据，再同步增量数据
- 修改业务代码，写入数据不仅写入旧库，还要写入新库（加开关，实时控制）
- 抽样调查，数据核对
- 数据一致，可进行读切流，灰度切
- 继续保留双写，跑个几天，完全没问题了关闭旧库

还可以通过别的中间件进行数据同步，比如flink-cdc，支持异构同步（mysql同步到es）

